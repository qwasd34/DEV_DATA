{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qwasd34/DEV_DATA/blob/main/%5B%ED%85%8D%EC%8A%A4%ED%8A%B8%EB%A7%88%EC%9D%B4%EB%8B%9D%5D_%E1%84%90%E1%85%A9%E1%84%91%E1%85%B5%E1%86%A8_%E1%84%86%E1%85%A9%E1%84%83%E1%85%A6%E1%86%AF%E1%84%85%E1%85%B5%E1%86%BC_%E1%84%89%E1%85%B5%E1%86%AF%E1%84%89%E1%85%B3%E1%86%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Yelp 데이터셋에 잠재하는 주제를 찾아내기\n",
        "\n",
        "  입력: 전체 텍스트 문서 집합 / 토픽의수\n",
        "\n",
        "  출력:\n",
        "    문서별 토픽 분포 / 토픽별 단어분포"
      ],
      "metadata": {
        "id": "tUMGgja8BY0B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 단어 레벨로 토큰 설정\n",
        "- 기본적인 텍스트 데이터 전처리\n",
        "  - 토크나이즈 (띄어쓰기)\n",
        "  - Stop words 제거\n",
        "  - Stemming\n",
        "    - 많이 사용하는 PorterStemmer 사용\n",
        "  - 기타\n",
        "    - 소문자화(정규화) , 비단어적 요소 제거"
      ],
      "metadata": {
        "id": "r2gZo9xwBxD3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 로드\n",
        "\n"
      ],
      "metadata": {
        "id": "-k5FSOs0vH6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# txt 파일을 pandas의 형태로 변환하지 않고\n",
        "# 직접적으로 load\n",
        "# 과정에서 0 혹은 1 부분은 제거\n",
        "\n",
        "file_path = 'yelp_labelled.txt'\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as file :\n",
        "    data = [line.split('\\t')[0] for line in file]\n",
        "\n",
        "print(data[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfARFOXxANhv",
        "outputId": "b38b9b83-38b7-430c-e9f9-6373542619cc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Wow... Loved this place.', 'Crust is not good.', 'Not tasty and the texture was just nasty.', 'Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.', 'The selection on the menu was great and so were the prices.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 전처리 (Tokenize, Stop Words, Stemming + alpha)"
      ],
      "metadata": {
        "id": "qPDbrLVJAiiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def preprocessing(text) :\n",
        "    # 소문자 변환\n",
        "    text = text.lower()\n",
        "    # 비 단어적 요소 제거\n",
        "    text = re.sub(r'\\W', ' ', text)\n",
        "    # Tokeinize (띄어쓰기 단위로)\n",
        "    text = text.split()\n",
        "    # Stop words 제거\n",
        "    text = [t for t in text if t not in stop_words]\n",
        "    # 어간 추출\n",
        "    text = [stemmer.stem(word) for word in text]\n",
        "    return text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MM5M1dZJHGzR",
        "outputId": "f3c84834-9f3c-42e1-ef28-1681bcff8583"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for d in data[:5] :\n",
        "    print(f'원래 문장 : {d}')\n",
        "    print(f'전처리 후 문장 : {preprocessing(d)}')\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3ZST1TtHraZ",
        "outputId": "ae6f67d7-7107-4ede-a82a-e9f4432afb3f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원래 문장 : Wow... Loved this place.\n",
            "전처리 후 문장 : ['wow', 'love', 'place']\n",
            "\n",
            "원래 문장 : Crust is not good.\n",
            "전처리 후 문장 : ['crust', 'good']\n",
            "\n",
            "원래 문장 : Not tasty and the texture was just nasty.\n",
            "전처리 후 문장 : ['tasti', 'textur', 'nasti']\n",
            "\n",
            "원래 문장 : Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.\n",
            "전처리 후 문장 : ['stop', 'late', 'may', 'bank', 'holiday', 'rick', 'steve', 'recommend', 'love']\n",
            "\n",
            "원래 문장 : The selection on the menu was great and so were the prices.\n",
            "전처리 후 문장 : ['select', 'menu', 'great', 'price']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preproc_data = [preprocessing(d) for d in data]\n",
        "preproc_data[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsGAVBgDJZcB",
        "outputId": "ed4658fd-8ac5-4895-b471-40e3705403b3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['wow', 'love', 'place'],\n",
              " ['crust', 'good'],\n",
              " ['tasti', 'textur', 'nasti'],\n",
              " ['stop',\n",
              "  'late',\n",
              "  'may',\n",
              "  'bank',\n",
              "  'holiday',\n",
              "  'rick',\n",
              "  'steve',\n",
              "  'recommend',\n",
              "  'love'],\n",
              " ['select', 'menu', 'great', 'price']]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LDA 모델 적용하기"
      ],
      "metadata": {
        "id": "J1nMzgnXJuJT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Document-Term Matrix 생성"
      ],
      "metadata": {
        "id": "MpzcM4fZHx9y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 문서 단어 행렬 (DTM)\n",
        "\n",
        "- 전처리된 데이터에서 각단어의 빈도를 나타내는 행렬 생성\n",
        "- 행의 방향으로 문서를 나타내며, 열의 방향으로 단어를 나타냄\n",
        "- 어떤 열번호 index에 어떤 단어 term 가 들어갈지 정해야함\n",
        "  - Gensim 패키지의 Dictionary Class 이용\n",
        "- 만들어진 단어 term - 번호index 객체를 활용 DTM 생성\n",
        "  - (단어 ID, 빈도수) 의 형태"
      ],
      "metadata": {
        "id": "rKxJkfIvCeh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import corpora\n",
        "\n",
        "# Gensim의 Dictionary 객체를 생성\n",
        "dictionary = corpora.Dictionary(preproc_data)"
      ],
      "metadata": {
        "id": "UYUukqrkHmc2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(dictionary.token2id.items())[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbpcfjMQKVy-",
        "outputId": "b17c8012-40dd-422c-f364-56d62594d422"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('love', 0),\n",
              " ('place', 1),\n",
              " ('wow', 2),\n",
              " ('crust', 3),\n",
              " ('good', 4),\n",
              " ('nasti', 5),\n",
              " ('tasti', 6),\n",
              " ('textur', 7),\n",
              " ('bank', 8),\n",
              " ('holiday', 9)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문서-단어 행렬을 생성\n",
        "corpus = [dictionary.doc2bow(text) for text in preproc_data]"
      ],
      "metadata": {
        "id": "BwhmtmuKIyTZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫 번째 문장의 DTM\n",
        "# 0번째 단어가 1번 1번째 단어가 1번 ...!\n",
        "corpus[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McPumn2yOwum",
        "outputId": "0f6dc711-522f-49b3-b2fd-220e158f57ac"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 1), (1, 1), (2, 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이는 0번째 단어가 1번, 1번째 단어가 1번, 2번째 단어가 1번 나옴을 의미\n",
        "# 각 단어를 확인하기 위해서는 아래의 과정을 통해 알 수 있음\n",
        "\n",
        "print(f'0 번째 단어 : {dictionary[0]}')\n",
        "print(f'1 번째 단어 : {dictionary[1]}')\n",
        "print(f'2 번째 단어 : {dictionary[2]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qz0lx7WmOws0",
        "outputId": "97da37df-15ca-4ed0-dc46-e8aea4c8942a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 번째 단어 : love\n",
            "1 번째 단어 : place\n",
            "2 번째 단어 : wow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LDA 적용"
      ],
      "metadata": {
        "id": "oJpn6JAlJR3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import ldamodel\n",
        "\n",
        "topicK = 3\n",
        "num_trains = 10\n",
        "\n",
        "lda_model = ldamodel.LdaModel(corpus,\n",
        "                              num_topics=topicK, # 선정한 토픽 수\n",
        "                              id2word=dictionary,# 몇번째 단어가 무엇인지\n",
        "                              passes=num_trains, # 학습 횟수\n",
        "                              random_state=42)"
      ],
      "metadata": {
        "id": "mQUPQ_nsIW7p"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 토픽 별 단어 분포 확인 (토픽, 그토픽을 구성하는데 얼만큼 쓰였는지)\n",
        "for k in range(topicK):\n",
        "    print(lda_model.show_topic(k, topn=20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLW2lywdbfPg",
        "outputId": "50d427ba-7ff1-413d-f546-1239f28ff80d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('servic', 0.017086321), ('good', 0.014856899), ('disappoint', 0.010963259), ('like', 0.009364962), ('best', 0.009119847), ('great', 0.008761751), ('also', 0.00869444), ('realli', 0.008605385), ('place', 0.008238193), ('staff', 0.007839445), ('friendli', 0.007232641), ('order', 0.006750442), ('eat', 0.0066319024), ('nice', 0.0062933825), ('could', 0.0058348477), ('steak', 0.0052713323), ('amaz', 0.005116638), ('even', 0.0050651086), ('know', 0.004823529), ('burger', 0.004761508)]\n",
            "[('food', 0.042987805), ('back', 0.02138683), ('good', 0.019900084), ('servic', 0.017604794), ('place', 0.017388444), ('go', 0.017267667), ('time', 0.011744485), ('wait', 0.010304522), ('would', 0.008815033), ('ever', 0.0072248215), ('love', 0.0067911996), ('minut', 0.006650361), ('never', 0.006449497), ('come', 0.0062793614), ('pizza', 0.0056791217), ('like', 0.0056220596), ('vega', 0.005453013), ('want', 0.005266863), ('great', 0.0050176657), ('recommend', 0.0048496644)]\n",
            "[('place', 0.021426972), ('great', 0.017665138), ('restaur', 0.007841083), ('like', 0.0073311613), ('salad', 0.0071722586), ('star', 0.006963248), ('delici', 0.0064564915), ('time', 0.0063532447), ('get', 0.0053818994), ('pretti', 0.005359296), ('way', 0.0053427666), ('enough', 0.00500764), ('realli', 0.0050020404), ('experi', 0.0049468493), ('got', 0.0049142884), ('fri', 0.004801186), ('one', 0.0047682333), ('worth', 0.0047049844), ('much', 0.004480668), ('flavor', 0.0044741654)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문서 별 토픽 분포 확인\n",
        "for document in corpus[:5]:\n",
        "    origin_doc = [dictionary[word_idx] for word_idx, word_num in document]\n",
        "    print(f'{origin_doc}에 속한 토픽의 분포는 아래와 같습니다.')\n",
        "    for topic_idx, topic_dist in lda_model[document]:\n",
        "        print(f'{topic_idx} 번째 토픽 : {topic_dist*100:.2f}% 확률')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATbG4AF8ScQY",
        "outputId": "64416bae-b74e-4040-adda-8e12513a01a5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['love', 'place', 'wow']에 속한 토픽의 분포는 아래와 같습니다.\n",
            "0 번째 토픽 : 8.79% 확률\n",
            "1 번째 토픽 : 10.01% 확률\n",
            "2 번째 토픽 : 81.20% 확률\n",
            "['crust', 'good']에 속한 토픽의 분포는 아래와 같습니다.\n",
            "0 번째 토픽 : 75.95% 확률\n",
            "1 번째 토픽 : 12.74% 확률\n",
            "2 번째 토픽 : 11.31% 확률\n",
            "['nasti', 'tasti', 'textur']에 속한 토픽의 분포는 아래와 같습니다.\n",
            "0 번째 토픽 : 11.01% 확률\n",
            "1 번째 토픽 : 80.56% 확률\n",
            "2 번째 토픽 : 8.43% 확률\n",
            "['love', 'bank', 'holiday', 'late', 'may', 'recommend', 'rick', 'steve', 'stop']에 속한 토픽의 분포는 아래와 같습니다.\n",
            "0 번째 토픽 : 3.47% 확률\n",
            "1 번째 토픽 : 93.11% 확률\n",
            "2 번째 토픽 : 3.43% 확률\n",
            "['great', 'menu', 'price', 'select']에 속한 토픽의 분포는 아래와 같습니다.\n",
            "0 번째 토픽 : 35.37% 확률\n",
            "1 번째 토픽 : 7.65% 확률\n",
            "2 번째 토픽 : 56.98% 확률\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 토픽 별 단어 분포 확인\n",
        "for k in range(topicK):\n",
        "    print(f'{k}번째 토픽을 구성하는 단어의 분포는...')\n",
        "    for word, prob in lda_model.show_topic(k, topn=5) :\n",
        "        print(f'{word} : {prob*100:.2f}%', end= ' ')\n",
        "    print()\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu99d-wTT1EO",
        "outputId": "07a0c4fb-77ac-4432-94b9-a8247ba637c1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0번째 토픽을 구성하는 단어의 분포는...\n",
            "servic : 1.71% good : 1.49% disappoint : 1.10% like : 0.94% best : 0.91% \n",
            "\n",
            "1번째 토픽을 구성하는 단어의 분포는...\n",
            "food : 4.30% back : 2.14% good : 1.99% servic : 1.76% place : 1.74% \n",
            "\n",
            "2번째 토픽을 구성하는 단어의 분포는...\n",
            "place : 2.14% great : 1.77% restaur : 0.78% like : 0.73% salad : 0.72% \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LDA 모델 결과 해석하기"
      ],
      "metadata": {
        "id": "8q7-AfTpZWqd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 토픽의 의미는 사용자가 선정해야함\n",
        "  - 토픽을 구정하는 단어를 보고 토픽의 의미를 선정\n"
      ],
      "metadata": {
        "id": "PviWhd0pHcaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0번째 토픽을 구성하는 상위 10개 단어\n",
        "for word, prob in lda_model.show_topic(0, topn=10):\n",
        "    print(f'{word}, {prob*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ts3DEbYkXgTj",
        "outputId": "620c960e-5048-44e3-af74-99d51b1144a6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "servic, 1.71%\n",
            "good, 1.49%\n",
            "disappoint, 1.10%\n",
            "like, 0.94%\n",
            "best, 0.91%\n",
            "great, 0.88%\n",
            "also, 0.87%\n",
            "realli, 0.86%\n",
            "place, 0.82%\n",
            "staff, 0.78%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 식당 서비스 품질과 고객 경험\n",
        "  - service best place staff"
      ],
      "metadata": {
        "id": "sKyc49XoHm0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1번째 토픽을 구성하는 상위 10개 단어\n",
        "for word, prob in lda_model.show_topic(1, topn=10):\n",
        "    print(f'{word}, {prob*100:.2f}%')"
      ],
      "metadata": {
        "id": "Zs8heFOxXzQH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5343cf5c-8f7c-400f-a574-b413cde8aba4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "food, 4.30%\n",
            "back, 2.14%\n",
            "good, 1.99%\n",
            "servic, 1.76%\n",
            "place, 1.74%\n",
            "go, 1.73%\n",
            "time, 1.17%\n",
            "wait, 1.03%\n",
            "would, 0.88%\n",
            "ever, 0.72%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 음식 품질과 재방문에 관련된 의사표현\n",
        "  -food back, good"
      ],
      "metadata": {
        "id": "b0HmEJIRHp04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2번째 토픽을 구성하는 상위 10개 단어\n",
        "for word, prob in lda_model.show_topic(2, topn=10):\n",
        "    print(f'{word}, {prob*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2ifSVNQatPO",
        "outputId": "91427494-a71d-405f-d6ab-c36f809be664"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "place, 2.14%\n",
            "great, 1.77%\n",
            "restaur, 0.78%\n",
            "like, 0.73%\n",
            "salad, 0.72%\n",
            "star, 0.70%\n",
            "delici, 0.65%\n",
            "time, 0.64%\n",
            "get, 0.54%\n",
            "pretti, 0.54%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 식당 전반의 분위기와 음식의 퀄리티\n",
        "  - place great restaurnt delicious"
      ],
      "metadata": {
        "id": "n9muBg4NHvzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 원문장과 토픽 분포를 보고 해석하기\n",
        "#랜덤한 인덱스\n",
        "target_idx = 10\n",
        "\n",
        "print('원 문장 : ', data[target_idx])\n",
        "print('전처리 문장 : ', preproc_data[target_idx])\n",
        "print('문장 내 토픽 분포 : ')\n",
        "for topic_idx, prob in lda_model[corpus[target_idx]]:\n",
        "    print(f'  - {topic_idx}번 토픽 : {prob*100:.2f}%')"
      ],
      "metadata": {
        "id": "2U3nS5o6czFs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5538485b-a30f-4924-c490-b3825d66fafe"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원 문장 :  Service was very prompt.\n",
            "전처리 문장 :  ['servic', 'prompt']\n",
            "문장 내 토픽 분포 : \n",
            "  - 0번 토픽 : 76.57%\n",
            "  - 1번 토픽 : 12.26%\n",
            "  - 2번 토픽 : 11.16%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "awNMgkRjy9W3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}